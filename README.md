# ESC_2022 Car Keeper README.md

**ğŸš™ Car Keeper(ì¹´í‚¤í¼)**     

## ğŸ§”ğŸ»FaceID 

## í•™ìŠµì„ í†µí•´ ì–¼êµ´ì˜ íŠ¹ì„± ì¶”ì¶œ


### íŒŒì¼ êµ¬ì¡°

```
...
|-- Image
    â””â”€â”€ user/
|-- User
|-- encodings.pickle
|-- FaceID.py
|-- FaceTrainFromImage.py
|-- Image_path
|-- Names
|-- README.md
|-- recognition.py
|-- requirements.txt
|-- SaveimgfromVideo.py
...
```

### 1. í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

```
pip install -r requirements.txt
```


### 2. í•™ìŠµì— í•„ìš”í•œ ì‚¬ì§„ ì¤€ë¹„

- Appì—ì„œ ì €ì¥ëœ ë™ì˜ìƒì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜ 
- SaveimgFromVideo.py
    <details>
    <summary>ì½”ë“œ </summary>
    <div markdown="1">

    ```python
    import cv2
    import os
    import time

    cap = cv2.VideoCapture(0)
    # cap = cv2.VideoCapture(0) ## ì›¹ìº 
    ## ë™ì˜ìƒ ê²½ë¡œ

    name_pattern = ".mp4"
    Name = "User1.mp4"
    Name = Name.replace(name_pattern, "")

    with open ("Names", "a") as txt:
        txt.write(Name + "\n")
    ## ì‚¬ìš©ì ë“±ë¡

    with open ("Image_path", "a") as txt:
        txt.write('Image/' + Name + "/\n")
        
    count = 1

    while cap.isOpened():
        ret, frame = cap.read()
        
        if not os.path.exists("Image"):
                    os.makedirs('Image')
                    os.makedirs("Image/"+Name)    
                        
        if not os.path.exists("Image/"+Name):  
            os.makedirs("Image/"+Name)              
                ## Imageê²½ë¡œê°€ ì—†ë‹¤ë©´ ë§Œë“œëŠ” ì½”ë“œ
        if not ret:
            print("ì¢…ë£Œ")
            break
        if(int(cap.get(1)) % 15 == 0):
        ## 10í”„ë ˆì„ë§ˆë‹¤ ì €ì¥  
        
            print('Saved frame number :' + str(int(cap.get(1))))
            cv2.imwrite("Image/"+Name+"/" + Name+ "%d.jpg" % count, frame, [cv2.IMWRITE_JPEG_QUALITY, 80])
            print('Saved frame%d.jpg' % count)
            time.sleep(0.2)
            ##0.2ì´ˆê°„ê²©
            count = count +1
            if(count == 21):
                break
                ## ìµœëŒ€ 20ì¥
    cap.release()

    ```

    </div>
    </details>



### 3. í•™ìŠµ ì‹œì‘

- ë¶„í• ëœ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ íŠ¹ì„± ì¶”ì¶œ
- FaceTrainFromImage.py
    <details>
    <summary> ì½”ë“œ </summary>
    <div markdown="1">

    ```python
    import enum
    import cv2
    import face_recognition
    import pickle
    import os
    import tensorflow as tf

    os.environ["CUDA_VISIBLE_DEVICES"]="0"
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        try:
            tf.config.experimental.set_memory_growth(gpus[0], True)
        except RuntimeError as e:
            print(e)


    Image_paths = []
    Names = []
    Image_num = 20
    image_type = '.jpg'
    encoding_file = 'encodings.pickle'
    model_method = 'CNN'
    ## CNN ì •í™•í•˜ì§€ë§Œ ëŠë¦¼
    ## HOG ë¹ ë¥´ì§€ë§Œ ì •í™•ë„ê°€ ë–¨ì–´ì§ 

    with open ("Image_path" , "r") as txt:
        Image_paths.append(txt.read().split())
    ## ì´ë¯¸ì§€ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°    
    with open ("Names" , "r") as txt:
        Names.append(txt.read().split())
        
    knownEncodings = []
    knownNames = []

    for (i, Image_path) in enumerate(Image_paths[0]):
        name = Names[0][i]
        print(name)
        
        
        for idx in range(Image_num):
            file_name = Image_path + name+ str(idx+1) + image_type
            print(file_name)
            
            image = cv2.imread(file_name, cv2.IMREAD_COLOR)
            rgb_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    # ################# ì €ì¥ëœ ê²½ë¡œì—ì„œ ì´ë¯¸ì§€ë¥¼ í•˜ë‚˜ì”© ì½ì–´ì˜´ ##################

            boxes = face_recognition.face_locations(rgb_img, 
                                                    model = model_method)  
            ##  face_recognitionì„ ì´ìš©í•˜ì—¬ ì–¼êµ´ ë¶€ë¶„ í™•ì¸ -> CNN ëª¨ë¸ ì‚¬ìš©
            
            encodings = face_recognition.face_encodings(image, boxes)
            ## face_recognitionì„ ì´ìš©í•˜ì—¬ ì–¼êµ´ íŠ¹ì§• ì¸ì½”ë”©  
            
            for encoding in encodings:
                print(file_name, name, encoding)
                knownEncodings.append(encoding)
                knownNames.append(name)
    #             ## ì¸ì½”ë”©ëœ ê°’ì„ ì €ì¥
                
    ## ìœ„ì—ì„œ ì–»ì€ ì •ë³´ë“¤ì„ íŒŒì¼ë¡œ ì €ì¥
    data = {"encodings": knownEncodings, "names": knownNames}
    f = open(encoding_file, "wb")
    f.write(pickle.dumps(data))    
    ```

    </div>
    </details>

### 4. ì‚¬ìš©ì ì¸ì‹ 

- í•™ìŠµë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬ ì‚¬ìš©ì ì–¼êµ´ ì¸ì‹ 
- recognition.py

    <details>
    <summary> ì½”ë“œ </summary>
    <div markdown="1">

    ```python
    import cv2
    import face_recognition
    import pickle
    import time
    import os
    import tensorflow as tf
    import numpy as np

    file_name = 'User/user.mp4'
    encoding_file = 'encodings.pickle'
    Unknow_name = 'Unknown'
    frame_resizing = 0.25
    model_method = 'CNN'

    def DetectAndDisplay(image,data):
        start_time = time.time()
        small_frame = cv2.resize(image, (0, 0), fx=frame_resizing, fy=frame_resizing)
        # small_frame = cv2.resize(image, (256,256), interpolation= cv2.INTER_LINEAR)
        rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)
        boxes = face_recognition.face_locations(rgb_small_frame,model=model_method)
        encodings = face_recognition.face_encodings(rgb_small_frame, boxes)
        
        names = []
        
        for encoding in encodings:
            matches = face_recognition.compare_faces(data["encodings"] ,
                                                    encoding)
            name = Unknow_name
            
            if True in matches:
                matchesIdxs = [i for (i,b) in enumerate(matches) if b]
                counts = {}
                
                for i in matchesIdxs:
                    name = data["names"][i]
                    print(name)
                    counts[name] = counts.get(name,0) +1
                    
                    
                name = max(counts, key = counts.get)
            names.append(name)
            boxes = np.array(boxes)
            boxes = boxes / frame_resizing
            boxes = boxes.astype(int)
            
        for face_loc, name in zip(boxes, names):
            
            top, left, bottom, right = face_loc[0], face_loc[1], face_loc[2], face_loc[3]
            cv2.putText(image, name, (left, top - 1), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 255, 0), 2)
            cv2.rectangle(image, (left,top), (right, bottom), (0, 0, 200), 4)
            
        end_time = time.time()
        print(end_time- start_time)
        
        # image = cv2.resize(frame, (0, 0), fx=frame_resizing, fy=frame_resizing)
        cv2.imshow("FACE", image)  


    ```
    </div>
    </details>


<!--
<details>
<summary>  </summary>
<div markdown="1">

</div>
</details>
----------------------
-->
